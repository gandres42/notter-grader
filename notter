#!./.venv/bin/python
import nbformat
from nbconvert.preprocessors import ExecutePreprocessor
from otter.api import grade_submission
from otter.run import run_autograder
import tempfile
import shutil
import time
import json
import os
import base64
import io
from PIL import Image
import numpy as np
import json

# TODO identify why some webp images don't load

# add local check to make local testing easier
LOCAL = os.getenv("HOSTNAME", "") == "wintermute"

# parse config.json
with open('config.json') as config_file:
    config = json.load(config_file)
MAX_SCORE = config['points_possible']
IMAGES_ONLY = config['output_images']
RESTART_RUN_ALL_CHECK = config['grade_restarted']

# auto pick out a notebook from the submission directory
if LOCAL:
    notebook_dir = './'
else:
    notebook_dir = '/autograder/source/'
notebook_name = sorted([f for f in os.listdir(notebook_dir) if f.endswith('.ipynb')])[0]
NOTEBOOK_PATH = f'{notebook_dir}{notebook_name}'

# move required files into the grading workspace
if LOCAL:
    directory_path = "./files"
else:
    directory_path = "/autograder/source/files"
REQUIRED_FILES = []
for root, dirs, filenames in os.walk(directory_path):
    for filename in filenames:
        relative_path = os.path.relpath(os.path.join(root, filename), directory_path)
        REQUIRED_FILES.append(relative_path)

# generate pretty output text
def otto_ascii_creator(gradescope_dict, total_score, total_possible):
    max_len = max([len(test['name']) for test in gradescope_dict['tests']])
    ascii_header = """

 _   _       _   _            
| \\ | |     | | | |           
|  \\| | ___ | |_| |_ ___ _ __ 
| . ` |/ _ \\| __| __/ _ \\ '__|
| |\\  | (_) | |_| ||  __/ |   
|_| \\_|\\___/ \\__|\\__\\___|_|   

------------------------------- GRADING SUMMARY --------------------------------"""

    summary = f'{"name".rjust(max_len)}  {"score".rjust(5)}  {"max_score".rjust(9)}\n'
    for test in gradescope_dict['tests']:
        if 'score' in test.keys():
            summary += f'{test['name'].rjust(max_len)}  {str(float(test['score'])).rjust(5)}  {str(float(test['max_score'])).rjust(9)}\n'
    header = f'Total Score: {round(total_score, 3)} / {round(total_possible, 3)} ({round((total_score / total_possible) * 100, 3)}%)'
    summary = f'{ascii_header}\n{header}\n\n{summary}'
    return summary

# check if all notebook cells have been run
def check_restart_runall(notebook):
    prev_count = 0
    strikes = 0
    for cell in notebook.cells:
        if cell.cell_type == "code":
            # if cell not increasing, add strike.  Otherwise reset strikes.
            if cell.execution_count != prev_count + 1:
                strikes += 1
            else:
                strikes = 0
            
            # if 3 strikes, they're out
            if strikes >= 3:
                return 0, "Did not restart and run all cells"
            
            if cell.execution_count != None:
                prev_count = cell.execution_count

    return 1, "Restarted and all cells run"

# clear notebook outputs
def clear_notebook(notebook):
    for cell in notebook.cells:
        if cell.cell_type == 'code':
            cell.outputs = []

# compress images until they're under the gradescope base64 limit
def image_compressor(base64_string, output_format="WEBP"):
    compressed_b64 = base64_string
    new_width = None
    while len(compressed_b64) >= 50000:
        image_data = base64.b64decode(compressed_b64)
        image = Image.open(io.BytesIO(image_data))
        if new_width is None:
            new_width = image.width
        else:
            aspect_ratio = image.height / image.width
            new_width = new_width - 50
            new_height = int(new_width * aspect_ratio)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)

        compressed_image_io = io.BytesIO()
        image.save(compressed_image_io, format=output_format, quality=50)
        compressed_b64 = base64.b64encode(compressed_image_io.getvalue()).decode("utf-8")
    # print(len(compressed_b64))
    return compressed_b64

# extract images from a notebook and return html representation
def image_html_factory(notebook):
    html_content = '<!DOCTYPE html><html><body style="display: flex; justify-content: center; align-items: center;"><div style="display: flex; flex-direction: column; align-content: center;">'
    # Iterate through the cells to find image outputs
    for cell in notebook.get("cells", []):
        if cell.get("cell_type") == "code":
            for output in cell.get("outputs", []):
                if output.get("output_type") == "display_data":
                    image_data = output.get("data", {}).get("image/png")
                    if image_data:
                        new_data = image_compressor(image_data)
                        new_html = f'<img src="data:image/png;base64,{new_data}" style="width:100%; margin-bottom:10px; max-width: 900px;" />'
                        html_content = html_content + new_html
    html_content = html_content + '</div></body></html>'
    return html_content

# grade a notebook and output results as results.json
def score_notebook(notebook_path):
    with tempfile.NamedTemporaryFile(suffix=".ipynb", delete=False) as tmp_notebook:
        # read original into copy, open it with nbformat
        tmp_notebook_path = tmp_notebook.name
        shutil.copyfile(notebook_path, tmp_notebook_path)
        tmp_notebook = nbformat.read(tmp_notebook, as_version=4)

        # check if the code has been restarted/run all
        restart_score, restart_msg = check_restart_runall(tmp_notebook)

        # clear tmp_notebook outputs
        clear_notebook(tmp_notebook)

        # run all cells in tmp_notebook, ignore errors
        execute_preprocessor = ExecutePreprocessor(timeout=None, allow_errors=True)
        start_time = time.monotonic()
        execute_preprocessor.preprocess(tmp_notebook, {'metadata': {'path': '.'}})
        end_time = time.monotonic()

        # grade complete notebook
        if LOCAL:
            otter_results = grade_submission(tmp_notebook_path, 'autograder.zip', quiet=True)
        else:
            otter_results = grade_submission(tmp_notebook_path, '/autograder/source/autograder.zip', quiet=True)
        
        gradescope_results = {}
        
        # save per-test results for gradescope results
        config = run_autograder.autograder_config.AutograderConfig(user_config={})
        gradescope_results['tests'] = otter_results.to_gradescope_dict(config)['tests']
        
        # grade restart/run all penalty
        if RESTART_RUN_ALL_CHECK:
            gradescope_results['tests'].append({
                'name': 'restart/run all',
                'score': restart_score,
                'max_score': 1.0,
                'visibility': 'hidden',
                'output': restart_msg
            })

        # calculate total score with respect to configured max score
        total_possible = np.sum([test['max_score'] for test in gradescope_results['tests'][1:]])
        total_score = np.sum([test['score'] for test in gradescope_results['tests'][1:]])
        adjusted_score = total_score * (MAX_SCORE / total_possible)
        
        # put all this delectable data into results dictionary
        gradescope_results['execution_time'] = end_time - start_time
        gradescope_results['stdout_visibility'] = 'hidden'
        gradescope_results['score'] = adjusted_score
        if IMAGES_ONLY:
            html_body = image_html_factory(tmp_notebook)
            if LOCAL:
                with open('results.html', 'w', encoding='utf-8') as f:
                    f.write(html_body)
                    print(otto_ascii_creator(gradescope_results, adjusted_score, MAX_SCORE))
            gradescope_results['output'] = html_body
            gradescope_results['output_format'] = 'html'
        
        # print score to stdout
        print(otto_ascii_creator(gradescope_results, adjusted_score, MAX_SCORE))

        # dump results into results.json for gradescope
        json_string = json.dumps(gradescope_results, ensure_ascii=False)
        if LOCAL:
            with open('./results.json', "w") as json_file:
                json_file.write(json_string)
        else:
            with open('/autograder/results/results.json', "w") as json_file:
                json_file.write(json_string)

score_notebook(NOTEBOOK_PATH)